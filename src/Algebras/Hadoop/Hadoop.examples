Database: opt
Restore : NO

Operator : spread
Number   : 1
Signature:  
Example  : let dis_file_list = plz feed spread["plz",'',1;PLZ,5,TRUE;Ort,10,TRUE] 
Result   : crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator : spreadFiles
Number   : 1
Signature:  
Example  : query plz feed fdistribute["plz",'./',PLZ;3,TRUE;;] count; query spreadFiles("plz",'',3);
Result   : crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator : collect
Number   : 1
Signature:  
Example  : query dis_file_list collect[0,0] count
Result   : crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator : para
Number   : 1
Signature:  
Example  : query para(dis_file_list) 
Result   : crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator: TPARA
Number: 1
Signature: ( flist(ANY) ) -> ANY
Example  : query plz feed spread[ ; PLZ, 5, TRUE ; ] hadoopMap[ ; . consume];
Result: crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator: TPARA2
Number: 1
Signature: ( ANY1 x flist(ANY2) ) -> ANY2
Example  : let SubFileRel = plz feed spread[;PLZ,5,TRUE;]; query SubFileRel SubFileRel hadoopReduce2[ PLZ, PLZ, DLF, 5; . .. {n} hashjoin[PLZ, PLZ_n] ] collect[] count;
Result: crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator : createFList
Number   : 1
Signature: T x [string x rel x bool]-> flist(T)
Example  : let locRel = [const rel(tuple([Row:int, DS:int, Column:int, Path:text])) value ()]; query plz feed createFList["", locRel, DLF, FALSE];
Result   : crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator : hadoopMap
Number   : 1
Signature: flist(T) x [string] x [text] x [(DLO):DLF] x [bool] x ( map T T1 ) -> flist(T1)
Example  : query plz feed spread[ ; PLZ, 5, TRUE ; ] hadoopMap[ ; . consume];
Result   : crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator : hadoopReduce
Number   : 1
Signature: flist(T) x partAttr x [string] x [text] x [(DLO):DLF] x ( map T T1 ) -> flist(T1)
Example  : query plz feed spread[ ; PLZ, 5, TRUE ; ] hadoopMap[ ; . consume] hadoopReduce[ Ort ; . feed consume];
Result   : crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator : hadoopReduce2
Number   : 1
Signature: flist(T1) x flist(T2) x partAttr1 x partAttr2 x [string] x [text] x [(DLO):DLF] x [int] x ( map (T1 T2) T3 ) -> flist(T3)
Example  : let SubFileRel = plz feed spread[;PLZ,5,TRUE;]; query SubFileRel SubFileRel hadoopReduce2[ PLZ, PLZ, DLF, 5; . .. {n} hashjoin[PLZ, PLZ_n] ] collect[] count;
Result   : crashes
Remark   : Lack of  Parallel Secondo installation. 

Operator : pffeed
Number   : 1
Signature: stream(tuple(aR:int, aC:int, aD:int, ...)) x aR x aC x aD x fileName x [filePath] x [attemptTimes] x [T1] x [T2] -> stream(tuple())
Example  : query [const rel(tuple([Row:int, Column:int, Dest:int])) value ((1 1 1)(2 1 2)(3 1 1)(4 1 2)(5 1 1))] feed pffeed[Row, Column, Dest, "plz",1;] count = dis_file_list collect[0,1] count 
Result   : crashes
Remark   : Collect the first column of the flist created in the example of spread operator. Doesn't work since there is a lack of parallel processing configurations normally.

Operator : pffeed2
Number   : 1
Signature: stream(tuple(aR:int, aC:int, aD:int, ...)) x aR x aC x aD x fileName x [filePath] x [attemptTimes] x [T1] x [T2] -> stream(tuple())
Example  : query [const rel(tuple([Row:int, Column:int, Dest:int])) value ((1 1 1)(2 1 2)(3 1 1)(4 1 2)(5 1 1))] feed pffeed2[Row, Column, Dest, "plz",1;] count = dis_file_list collect[0,1] count 
Result   : crashes
Remark   : Collect the first column of the flist created in the example of spread operator. Doesn't work since there is a lack of parallel processing configurations normally.

Operator : pffeed3
Number   : 1
Signature: stream(tuple(aR:int, aC:int, aD:int, ...)) x aR x aC x aD x fileName x [filePath] x [attemptTimes] x [T1] x [T2] -> stream(tuple())
Example  : query [const rel(tuple([Row:int, Column:int, Dest:int])) value ((1 1 1)(2 1 2)(3 1 1)(4 1 2)(5 1 1))] feed pffeed3[Row, Column, Dest, "plz",1;] count = dis_file_list collect[0,1] count 
Result   : crashes
Remark   : Collect the first column of the flist created in the example of spread operator. Doesn't work since there is a lack of parallel processing configurations normally.

Operator : hadoopMapAll
Number   : 1
Signature: T -> stream(tuple(Row:int, DS:int, Column:int, Path:text)) 
Example  : query divide_osm('example.osm',"subExampleFile",12,"City"); query spreadFiles("subExampleFile",'',12); query hadoopMapAll(fullosmimport(totext("subExampleFile","City")))
Result   : crashes
Remark   : Collect the first column of the flist created in the example of spread operator. Doesn't work since there is a lack of parallel processing configurations normally.
